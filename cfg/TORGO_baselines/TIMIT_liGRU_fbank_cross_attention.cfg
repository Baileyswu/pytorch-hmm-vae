[cfg_proto]
cfg_proto = proto/global.proto
cfg_proto_chunk = proto/global_chunk.proto

[exp]
cmd = 
run_nn_script = run_nn
out_folder = exp/TIMIT_liGRU_fbank_attention
seed = 1234
use_cuda = True
gpu_id = cuda:3
multi_gpu = False
save_gpumem = False
n_epochs_tr = 24
 
[dataset1]
data_name = TIMIT_tr
fea = fea_name=mfcc
	fea_lst=/home/danliwoo/gplab/kaldi/egs/timit/s5/data/train/feats_mfcc.scp
	fea_opts=apply-cmvn --utt2spk=ark:/home/danliwoo/gplab/kaldi/egs/timit/s5/data/train/utt2spk  ark:/home/danliwoo/gplab/kaldi/egs/timit/s5/mfcc/train_cmvn_speaker.ark ark:- ark:- | add-deltas --delta-order=2 ark:- ark:- |
	cw_left=0
	cw_right=0
	
	fea_name=fbank
	fea_lst=/home/danliwoo/gplab/kaldi/egs/timit/s5/data/train/feats_fbank.scp
	fea_opts=apply-cmvn --utt2spk=ark:/home/danliwoo/gplab/kaldi/egs/timit/s5/data/train/utt2spk  ark:/home/danliwoo/gplab/kaldi/egs/timit/s5/fbank/cmvn_train.ark ark:- ark:- | add-deltas --delta-order=0 ark:- ark:- |
	cw_left=0
	cw_right=0

lab = lab_name=lab_cd
	lab_folder=/home/danliwoo/gplab/kaldi/egs/timit/s5/exp/dnn4_pretrain-dbn_dnn_ali
	lab_opts=ali-to-pdf
	lab_count_file=auto
	lab_data_folder=/home/danliwoo/gplab/kaldi/egs/timit/s5/data/train/
	lab_graph=/home/danliwoo/gplab/kaldi/egs/timit/s5/graph
	
	lab_name=lab_mono
	lab_folder=/home/danliwoo/gplab/kaldi/egs/timit/s5/exp/dnn4_pretrain-dbn_dnn_ali
	lab_opts=ali-to-phones --per-frame=true
	lab_count_file=none
	lab_data_folder=/home/danliwoo/gplab/kaldi/egs/timit/s5/data/train/
	lab_graph=/home/danliwoo/gplab/kaldi/egs/timit/s5/graph
n_chunks = 5

[dataset2]
data_name = TIMIT_dev
fea = fea_name=mfcc
	fea_lst=/home/danliwoo/gplab/kaldi/egs/timit/s5/data/dev/feats_mfcc.scp
	fea_opts=apply-cmvn --utt2spk=ark:/home/danliwoo/gplab/kaldi/egs/timit/s5/data/dev/utt2spk  ark:/home/danliwoo/gplab/kaldi/egs/timit/s5/mfcc/dev_cmvn_speaker.ark ark:- ark:- | add-deltas --delta-order=2 ark:- ark:- |
	cw_left=0
	cw_right=0
	
	fea_name=fbank
	fea_lst=/home/danliwoo/gplab/kaldi/egs/timit/s5/data/dev/feats_fbank.scp
	fea_opts=apply-cmvn --utt2spk=ark:/home/danliwoo/gplab/kaldi/egs/timit/s5/data/dev/utt2spk  ark:/home/danliwoo/gplab/kaldi/egs/timit/s5/fbank/cmvn_dev.ark ark:- ark:- | add-deltas --delta-order=0 ark:- ark:- |
	cw_left=0
	cw_right=0
lab = lab_name=lab_cd
	lab_folder=/home/danliwoo/gplab/kaldi/egs/timit/s5/exp/dnn4_pretrain-dbn_dnn_ali_dev
	lab_opts=ali-to-pdf
	lab_count_file=auto
	lab_data_folder=/home/danliwoo/gplab/kaldi/egs/timit/s5/data/dev/
	lab_graph=/home/danliwoo/gplab/kaldi/egs/timit/s5/graph
	
	lab_name=lab_mono
	lab_folder=/home/danliwoo/gplab/kaldi/egs/timit/s5/exp/dnn4_pretrain-dbn_dnn_ali_dev
	lab_opts=ali-to-phones --per-frame=true
	lab_count_file=none
	lab_data_folder=/home/danliwoo/gplab/kaldi/egs/timit/s5/data/dev/
	lab_graph=/home/danliwoo/gplab/kaldi/egs/timit/s5/graph
n_chunks = 1

[dataset3]
data_name = TIMIT_test
fea = fea_name=mfcc
	fea_lst=/home/danliwoo/gplab/kaldi/egs/timit/s5/data/test/feats_mfcc.scp
	fea_opts=apply-cmvn --utt2spk=ark:/home/danliwoo/gplab/kaldi/egs/timit/s5/data/test/utt2spk  ark:/home/danliwoo/gplab/kaldi/egs/timit/s5/mfcc/test_cmvn_speaker.ark ark:- ark:- | add-deltas --delta-order=2 ark:- ark:- |
	cw_left=0
	cw_right=0
	
	fea_name=fbank
	fea_lst=/home/danliwoo/gplab/kaldi/egs/timit/s5/data/test/feats_fbank.scp
	fea_opts=apply-cmvn --utt2spk=ark:/home/danliwoo/gplab/kaldi/egs/timit/s5/data/test/utt2spk  ark:/home/danliwoo/gplab/kaldi/egs/timit/s5/fbank/cmvn_test.ark ark:- ark:- | add-deltas --delta-order=0 ark:- ark:- |
	cw_left=0
	cw_right=0

lab = lab_name=lab_cd
	lab_folder=/home/danliwoo/gplab/kaldi/egs/timit/s5/exp/dnn4_pretrain-dbn_dnn_ali_test
	lab_opts=ali-to-pdf
	lab_count_file=auto
	lab_data_folder=/home/danliwoo/gplab/kaldi/egs/timit/s5/data/test/
	lab_graph=/home/danliwoo/gplab/kaldi/egs/timit/s5/graph
	
	lab_name=lab_mono
	lab_folder=/home/danliwoo/gplab/kaldi/egs/timit/s5/exp/dnn4_pretrain-dbn_dnn_ali_test
	lab_opts=ali-to-phones --per-frame=true
	lab_count_file=none
	lab_data_folder=/home/danliwoo/gplab/kaldi/egs/timit/s5/data/test/
	lab_graph=/home/danliwoo/gplab/kaldi/egs/timit/s5/graph
n_chunks = 1

[data_use]
train_with = TIMIT_tr
valid_with = TIMIT_dev
forward_with = TIMIT_test

[batches]
batch_size_train = 8
max_seq_length_train = 1000
increase_seq_length_train = True
start_seq_len_train = 100
multply_factor_seq_len_train = 2
batch_size_valid = 8
max_seq_length_valid = 1000

[architecture1]
arch_name = liGRU_layers1
arch_proto = proto/liGRU.proto
arch_library = neural_networks
arch_class = liGRU
arch_pretrain_file = none
arch_freeze = False
arch_seq_model = True
ligru_lay = 550,550,550,550,550
ligru_drop = 0.2,0.2,0.2,0.2,0.2
ligru_use_laynorm_inp = False
ligru_use_batchnorm_inp = False
ligru_use_laynorm = False,False,False,False,False
ligru_use_batchnorm = True,True,True,True,True
ligru_bidir = True
ligru_act = relu,relu,relu,relu,relu
ligru_orthinit = True
arch_lr = 0.0004
arch_halving_factor = 0.5
arch_improvement_threshold = 0.001
arch_opt = rmsprop
opt_momentum = 0.0
opt_alpha = 0.95
opt_eps = 1e-8
opt_centered = False
opt_weight_decay = 0.0

[architecture8]
arch_name = liGRU_layers2
arch_proto = proto/liGRU.proto
arch_library = neural_networks
arch_class = liGRU
arch_pretrain_file = none
arch_freeze = False
arch_seq_model = True
ligru_lay = 540,540,540,540,540
ligru_drop = 0.2,0.2,0.2,0.2,0.2
ligru_use_laynorm_inp = False
ligru_use_batchnorm_inp = False
ligru_use_laynorm = False,False,False,False,False
ligru_use_batchnorm = True,True,True,True,True
ligru_bidir = True
ligru_act = relu,relu,relu,relu,relu
ligru_orthinit = True
arch_lr = 0.0004
arch_halving_factor = 0.5
arch_improvement_threshold = 0.001
arch_opt = rmsprop
opt_momentum = 0.0
opt_alpha = 0.95
opt_eps = 1e-8
opt_centered = False
opt_weight_decay = 0.0

[architecture2]
arch_name = MLP_layers
arch_proto = proto/MLP.proto
arch_library = neural_networks
arch_class = MLP
arch_pretrain_file = none
arch_freeze = False
arch_seq_model = False
dnn_lay = N_out_lab_cd
dnn_drop = 0.0
dnn_use_laynorm_inp = False
dnn_use_batchnorm_inp = False
dnn_use_batchnorm = False
dnn_use_laynorm = False
dnn_act = softmax
arch_lr = 0.0004
arch_halving_factor = 0.5
arch_improvement_threshold = 0.001
arch_opt = rmsprop
opt_momentum = 0.0
opt_alpha = 0.95
opt_eps = 1e-8
opt_centered = False
opt_weight_decay = 0.0

[architecture3]
arch_name = MLP_layers2
arch_proto = proto/MLP.proto
arch_library = neural_networks
arch_class = MLP
arch_pretrain_file = none
arch_freeze = False
arch_seq_model = False
dnn_lay = N_out_lab_mono
dnn_drop = 0.0
dnn_use_laynorm_inp = False
dnn_use_batchnorm_inp = False
dnn_use_batchnorm = False
dnn_use_laynorm = False
dnn_act = softmax
arch_lr = 0.0004
arch_halving_factor = 0.5
arch_improvement_threshold = 0.001
arch_opt = rmsprop
opt_momentum = 0.0
opt_alpha = 0.95
opt_eps = 1e-8
opt_centered = False
opt_weight_decay = 0.0

[architecture4]
arch_name = CrossAtt1
arch_proto = proto/CrossAtt.proto
arch_library = myDNN
arch_class = MultiHeadCrossAttention
arch_pretrain_file = none
arch_freeze = False
arch_seq_model = False
crossatt_n_head= 4
crossatt_d_k = 64
crossatt_d_v = 64
crossatt_dropout = 0.1
arch_lr = 0.0004
arch_halving_factor = 0.5
arch_improvement_threshold = 0.001
arch_opt = rmsprop
opt_momentum = 0.0
opt_alpha = 0.95
opt_eps = 1e-8
opt_centered = False
opt_weight_decay = 0.

[architecture5]
arch_name = CrossAtt2
arch_proto = proto/CrossAtt.proto
arch_library = myDNN
arch_class = MultiHeadCrossAttention
arch_pretrain_file = none
arch_freeze = False
arch_seq_model = False
crossatt_n_head= 4
crossatt_d_k= 64
crossatt_d_v= 64
crossatt_dropout = 0.1
arch_lr = 0.0004
arch_halving_factor = 0.5
arch_improvement_threshold = 0.001
arch_opt = rmsprop
opt_momentum = 0.0
opt_alpha = 0.95
opt_eps = 1e-8
opt_centered = False
opt_weight_decay = 0.0

[architecture6]
arch_name = SelfAtt1
arch_proto = proto/SelfAtt.proto
arch_library = myDNN
arch_class = MultiHeadAttention
arch_pretrain_file = none
arch_freeze = False
arch_seq_model = False
selfatt_n_head= 4
selfatt_d_k= 64
selfatt_d_v= 64
selfatt_dropout = 0.1
arch_lr = 0.0004
arch_halving_factor = 0.5
arch_improvement_threshold = 0.001
arch_opt = rmsprop
opt_momentum = 0.0
opt_alpha = 0.95
opt_eps = 1e-8
opt_centered = False
opt_weight_decay = 0.0

[architecture7]
arch_name = SelfAtt2
arch_proto = proto/SelfAtt.proto
arch_library = myDNN
arch_class = MultiHeadAttention
arch_pretrain_file = none
arch_freeze = False
arch_seq_model = False
selfatt_n_head= 4
selfatt_d_k= 64
selfatt_d_v= 64
selfatt_dropout = 0.1
arch_lr = 0.0004
arch_halving_factor = 0.5
arch_improvement_threshold = 0.001
arch_opt = rmsprop
opt_momentum = 0.0
opt_alpha = 0.95
opt_eps = 1e-8
opt_centered = False
opt_weight_decay = 0.0

[model]
model_proto = proto/model.proto
model = x1=compute(liGRU_layers1,fbank)
	x2=compute(liGRU_layers2,fbank)
	x12=multi_combine(x1,x2)
	x21=multi_combine(x2,x1)
	y1=compute(CrossAtt1,x12)
	y2=compute(CrossAtt2,x21)
	w1=compute(SelfAtt1,y1)
	w2=compute(SelfAtt2,y2)
	w=concatenate(w1,w2)
	out_dnn2=compute(MLP_layers,w)
	out_dnn3=compute(MLP_layers2,w)
	loss_mono=cost_nll(out_dnn3,lab_mono)
	loss_mono_w=mult_constant(loss_mono,1.0)
	loss_cd=cost_nll(out_dnn2,lab_cd)
	loss_final=sum(loss_cd,loss_mono_w)
	err_final=cost_err(out_dnn2,lab_cd)

[forward]
forward_out = out_dnn2
normalize_posteriors = True
normalize_with_counts_from = lab_cd
save_out_file = False
require_decoding = True

[decoding]
decoding_script_folder = kaldi_decoding_scripts/
decoding_script = decode_dnn.sh
decoding_proto = proto/decoding.proto
min_active = 200
max_active = 7000
max_mem = 50000000
beam = 13.0
latbeam = 8.0
acwt = 0.2
max_arcs = -1
skip_scoring = false
scoring_script = local/score.sh
scoring_opts = "--min-lmwt 1 --max-lmwt 10"
norm_vars = False

